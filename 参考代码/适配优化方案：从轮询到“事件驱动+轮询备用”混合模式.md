您好，非常感谢您撰写如此完整和结构清晰的项目代码！这让我能够进行一次**极其深入和精准**的分析，并撰写以下“事件驱动”升级改造方案。

在详细审查grid_executor.py, strategy_controller.py, binance_connector.py, data_models.py, main.py, config.py 和 manual_cleanup.py 后，我确认您的项目已经具备了一个非常坚实的轮询式架构。现在，我们将对其进行一次**外科手术式的升级**，以实现“事件驱动为主，轮询为辅”的高性能模式。

### **适配优化方案：从轮询到“事件驱动+轮询备用”混合模式**

我们将分模块进行，每一步都清晰地说明**“为什么这么做”**和**“具体怎么做”**。

#### **第一步：升级 data_models.py - 基础强化**

当前的 data_models.py 已经很完善，我们只需做一个小小的增强，使其能更好地处理来自交易所的实时数据。

- **目标**: 增强TrackedOrder模型，使其能方便地从交易所返回的订单数据（无论是REST API还是WebSocket事件）中更新自身状态。
- **具体操作**:
  1. 在TrackedOrder类中添加一个status属性，用于直接反映交易所的订单状态字符串（如"NEW", "FILLED", "CANCELED"）。
  2. 添加一个update_from_exchange_data(self, order_data: Dict)方法，封装所有从字典更新属性的逻辑。

**修改后的 TrackedOrder (位于 data_models.py):**

```python
      # dual_grid_bot/data_models.py

class TrackedOrder(BaseModel):
    # ... (保留现有字段)
    order_id: Optional[str] = None
    client_order_id: Optional[str] = None # <-- 【新增】用于事件匹配
    status: str = "UNKNOWN" # <-- 【新增】直接反映交易所状态

    # ... (保留现有字段)
    
    def update_from_exchange_data(self, order_data: Dict[str, Any]) -> bool:
        """从交易所返回的订单字典中更新自身状态。"""
        try:
            self.status = order_data.get("status", self.status).upper()
            self.is_done = self.status in ["CLOSED", "CANCELED", "EXPIRED", "FILLED"]
            self.is_filled = self.status in ["CLOSED", "FILLED"]
            
            self.executed_amount_base = Decimal(str(order_data.get("filled", self.executed_amount_base)))
            self.executed_amount_quote = Decimal(str(order_data.get("cost", self.executed_amount_quote)))
            
            fee_info = order_data.get("fee")
            if fee_info and fee_info.get("cost"):
                self.cum_fees_quote = Decimal(str(fee_info.get("cost")))

            self.raw_info = order_data
            return True
        except Exception:
            return False
    
```

#### **第二步：改造 binance_connector.py - 成为事件的源头**

这是将轮询模式转变为事件驱动的**关键一步**。连接器需要被赋予“监听”的能力。

- **目标**: 让BinanceConnector能够连接到币安的User Data Stream，监听订单更新事件，并将这些事件推送到一个共享的队列中。
- **具体操作**:
  1. **引入事件队列**: 修改__init__方法，接收一个asyncio.Queue作为参数。
  2. **实现WebSocket逻辑**: 添加start_websocket, stop_websocket, _websocket_loop, _get_listen_key, _keep_listen_key_alive等方法。这部分逻辑将处理连接、自动重连和心跳维持。
  3. **事件推送**: 在WebSocket的消息处理方法_handle_ws_message中，当收到ORDER_TRADE_UPDATE事件时，将其打包并放入共享的事件队列中。

**修改建议 (binance_connector.py):**

```python
# dual_grid_bot/binance_connector.py
import asyncio
import websockets
# ... 其他 imports

class BinanceConnector:
    def __init__(self, ..., event_queue: asyncio.Queue): # <--【修改】
        # ...
        self.event_queue = event_queue # <--【新增】
        self.websocket_task: Optional[asyncio.Task] = None
        self._listen_key: Optional[str] = None
        # ...

    async def start(self): # <--【新增】
        """启动连接器的WebSocket监听。"""
        if self.websocket_task is None:
            self.websocket_task = asyncio.create_task(self._listen_to_ws())

    async def stop(self): # <--【新增】
        """停止连接器的WebSocket监听并关闭连接。"""
        if self.websocket_task:
            self.websocket_task.cancel()
        await self.exchange.close()

    # --- 【新增】完整的WebSocket监听逻辑 ---
    async def _get_listen_key(self) -> Optional[str]:
        # ... (实现获取 listen key 的逻辑)
    
    async def _keep_listen_key_alive(self):
        # ... (实现 listen key 续期的逻辑)

    async def _listen_to_ws(self):
        # ... (实现连接、重连、心跳的循环)
        # 伪代码:
        # while True:
        #     async with websockets.connect(...) as ws:
        #         while True:
        #             message = await ws.recv()
        #             await self._handle_ws_message(json.loads(message))

    async def _handle_ws_message(self, data: Dict[str, Any]):
        """处理收到的WebSocket消息，并将相关事件放入队列。"""
        event_type = data.get("e")
        if event_type == "ORDER_TRADE_UPDATE":
            order_data = data.get("o", {})
            event = {
                "event_type": "ORDER_UPDATE",
                "account_name": self.account_name,
                "data": order_data
            }
            await self.event_queue.put(event)
            self.logger.debug(f"Pushed order update event for {order_data.get('c')}")
    
    # ... 保留所有现有的REST API方法 (place_order, get_order_status等)
    
```



#### **第三步：重构 grid_executor.py - 从主动轮询到被动响应**

这是**最核心的改造**。我们将清理混乱的结构，并植入事件处理能力。

- **目标**:
  1. 确立control_task为唯一的周期性决策入口。
  2. 移除control_task中主动、频繁的订单状态轮询。
  3. 添加process_event方法来接收和处理来自控制器的事件，实时更新订单和层级状态。
  4. 实现一个低频的sync_orders_status_fallback方法作为备用，确保最终一致性。
- **具体操作**:
  1. 只保留一个名为control_task的async def方法。
  2. **添加process_event**:
     - 创建process_event(self, event_data: Dict)。
     - 内部通过event_data['c'] (clientOrderId) 匹配到对应的GridLevel和TrackedOrder。
     - 调用tracked_order.update_from_exchange_data(event_data)更新订单状态。
     - 调用level.update_state()更新层级状态。
  3. **添加备用轮询**:
     - 创建async def sync_orders_status_fallback(self)。
     - 遍历所有is_done=False的订单，通过await self.connector.get_order_status()获取最新状态并更新。
  4. **改造control_task**:
     - 移除对update_all_order_status的调用。
     - 在循环开始时，**可以**（但不是必须，可以更低频）调用一次await self.sync_orders_status_fallback()。
     - 保留update_grid_levels，因为它现在是基于**已被事件更新过**的TrackedOrder状态来分类GridLevel，这个操作依然是必要的。
     - 保留后续的所有决策逻辑（get_*_orders, place_*_order）。
  5. **修改下单逻辑**: 在adjust_and_place_*_order中，下单后将clientOrderId存入TrackedOrder.client_order_id，用于事件匹配。

**修改后的 GridExecutor 核心流程 (grid_executor.py):**

```python
      # dual_grid_bot/grid_executor.py

class GridExecutor:
    # ... (init, _generate_grid_levels等保持不变)
    
    def process_event(self, event_data: Dict[str, Any]):
        """【新增】处理单个订单事件的核心入口。"""
        client_order_id = event_data.get('c')
        
        target_level, tracked_order = None, None
        for level in self.grid_levels:
            if level.active_open_order and level.active_open_order.client_order_id == client_order_id:
                target_level, tracked_order = level, level.active_open_order
                break
            if level.active_close_order and level.active_close_order.client_order_id == client_order_id:
                target_level, tracked_order = level, level.active_close_order
                break

        if not target_level or not tracked_order:
            return # 事件与此执行器无关
            
        # 使用新方法更新订单状态
        tracked_order.update_from_exchange_data(event_data)
        self.logger.info(f"Event processed for order {client_order_id}, new status: {tracked_order.status}")
        
        # 状态更新后，层级的状态机也会随之改变
        target_level.update_state()

    async def sync_orders_status_fallback(self):
        """【新增】备用轮询，用于同步可能丢失的事件。"""
        # ... (实现低频轮询逻辑)

    async def control_task(self):
        """【重构】唯一的周期性控制任务。"""
        # 1. 【可选，低频】执行备用轮询
        # if time.time() - self.last_fallback_sync > 30: # e.g., every 30s
        #    await self.sync_orders_status_fallback()
        #    self.last_fallback_sync = time.time()

        # 2. 更新层级分类 (基于可能已被事件更新的状态)
        self.update_grid_levels()

        # 3. 核心决策逻辑 (这部分不变)
        open_orders_to_create = self.get_open_orders_to_create()
        # ... etc ...

        # 4. 执行决策 (这部分不变)
        for level in open_orders_to_create:
            await self.adjust_and_place_open_order(level)
        # ... etc ...
    
```

#### **第四步：升级 strategy_controller.py - 成为事件的分发中心**

控制器需要被改造成一个双循环驱动的模式。

- **目标**: 同时运行一个事件处理循环和一个周期性的control_task调用循环。
- **具体操作**:
  1. **创建共享队列**: 在__init__中创建self._event_queue = asyncio.Queue()。
  2. **传递队列**: 在initialize_connectors时，将self._event_queue传递给两个BinanceConnector的构造函数。
  3. **重构主循环**:
     - 创建一个新的_event_handler协程，它在一个while True循环中await self._event_queue.get()，然后根据account_name将事件分发给self.executor_long.process_event(...)或self.executor_short.process_event(...)。
     - 您现有的_run_executor_loop可以作为**第二个**循环，它依然定期调用executor.control_task()。
     - 在start方法中，使用asyncio.gather**并行启动**这两个循环。

**修改后的 StrategyController 主循环 (strategy_controller.py):**

```python
      # dual_grid_bot/strategy_controller.py

class StrategyController:
    def __init__(self):
        self._event_queue = asyncio.Queue() # <--【新增】
        # ...

    async def initialize_connectors(self):
        # ...
        self.connector_a = BinanceConnector(..., event_queue=self._event_queue) # <--【修改】
        self.connector_b = BinanceConnector(..., event_queue=self._event_queue) # <--【修改】
        # ...

    async def start(self):
        # ... (前面的步骤不变)
        # 启动执行器 (不再需要单独启动它们的循环)
        await self.executor_long.start()
        await self.executor_short.start()
        
        # 启动监控和事件处理
        await self.start_loops()

    async def start_loops(self): # <--【新增】
        """启动事件和控制双循环。"""
        self.monitor_task = asyncio.create_task(
            asyncio.gather(
                self._event_handler_loop(),
                self._executor_control_loop(),
                # 可以保留您原有的 _monitor_loop 用于全局健康检查
            )
        )
        
    async def _event_handler_loop(self): # <--【新增】
        """事件处理循环。"""
        while self.is_running:
            event = await self._event_queue.get()
            if event["account_name"] == self.connector_a.account_name:
                self.executor_long.process_event(event["data"])
            else:
                self.executor_short.process_event(event["data"])

    async def _executor_control_loop(self): # <--【重构】
        """执行器周期性控制循环。"""
        while self.is_running:
            await asyncio.gather(
                self.executor_long.control_task(),
                self.executor_short.control_task()
            )
            await asyncio.sleep(ALL_CONFIG["monitor"]["update_interval"])
    
```



这个详细的方案请您一步步地将现有项目升级为一个更加健壮、高效和专业的事件驱动系统，同时保留了轮询作为后备，完美复刻了Hummingbot的设计精髓。